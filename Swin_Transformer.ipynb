{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOCABfHzr9u503vlttjdKz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a1481b55fb714826bcf5058895f7bc2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37e180599785426898b5e23b6436cff1",
              "IPY_MODEL_eb141f1a65af4cfd9619c786b97ab7d0",
              "IPY_MODEL_99768b8601424da78e5839e7fc043d33"
            ],
            "layout": "IPY_MODEL_35f384e966a842e4839561639449a1c4"
          }
        },
        "37e180599785426898b5e23b6436cff1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90936f9536bf44c4aecd77e797e46178",
            "placeholder": "​",
            "style": "IPY_MODEL_c690efb72ac74a37b5ce17947886f3be",
            "value": "100%"
          }
        },
        "eb141f1a65af4cfd9619c786b97ab7d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f80ce5ff405435eb617c00b9ea5cb6e",
            "max": 114342173,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df027177afc243ebac097b9b2b55c11a",
            "value": 114342173
          }
        },
        "99768b8601424da78e5839e7fc043d33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dad2eca9a344c7486c17c7cf1c37249",
            "placeholder": "​",
            "style": "IPY_MODEL_2cc4a2cf1ca849e0807c221de558a504",
            "value": " 109M/109M [00:01&lt;00:00, 103MB/s]"
          }
        },
        "35f384e966a842e4839561639449a1c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90936f9536bf44c4aecd77e797e46178": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c690efb72ac74a37b5ce17947886f3be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f80ce5ff405435eb617c00b9ea5cb6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df027177afc243ebac097b9b2b55c11a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7dad2eca9a344c7486c17c7cf1c37249": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cc4a2cf1ca849e0807c221de558a504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RezuanChowdhuryRifat/SETI-Signal-Classification/blob/main/Swin_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports\n"
      ],
      "metadata": {
        "id": "TBTmMi-sUPcF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Xy0rhgnG3cv4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms as T \n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, sampler, random_split\n",
        "from torchvision import models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm \n",
        "import timm\n",
        "from timm.loss import LabelSmoothingCrossEntropy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4Wy8xx03osq",
        "outputId": "c18fe2b1-ea88-4797-fcf2-69de7e6975c6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.6.12-py3-none-any.whl (549 kB)\n",
            "\u001b[K     |████████████████████████████████| 549 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from timm) (6.0)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.7/dist-packages (from timm) (1.12.1+cu113)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 54.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.13.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7->timm) (4.1.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (4.13.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (3.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (4.64.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub->timm) (3.10.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->timm) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->timm) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->timm) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->timm) (2022.9.24)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Installing collected packages: huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.11.1 timm-0.6.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "IqBzoGQiUVJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5yucnTD4X2h",
        "outputId": "5768af2b-d3d7-4162-adeb-44215c5fe7a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYcAOA5i4wnL",
        "outputId": "09a027f8-5adc-4318-8308-733dcc34df25"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_classes(data_dir):\n",
        "    all_data = datasets.ImageFolder(data_dir)\n",
        "    return all_data.classes"
      ],
      "metadata": {
        "id": "7E3Q_hVy9A5d"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"/content/drive/MyDrive/dataset/train\"\n",
        "test_path = \"/content/drive/MyDrive/dataset/test\"\n",
        "valid_path = \"/content/drive/MyDrive/dataset/valid\"\n",
        "\n",
        "\n",
        "SIZE = 224  #Resize images\n",
        "batch_size = 32\n",
        "\n",
        "train_transform = T.Compose([\n",
        "            T.RandomHorizontalFlip(),\n",
        "            T.RandomVerticalFlip(),\n",
        "            T.Resize(256),\n",
        "            T.CenterCrop(224),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(timm.data.IMAGENET_DEFAULT_MEAN, timm.data.IMAGENET_DEFAULT_STD)\n",
        "        ])\n",
        "\n",
        "test_transform = T.Compose([\n",
        "            T.Resize(256),\n",
        "            T.CenterCrop(224),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(timm.data.IMAGENET_DEFAULT_MEAN, timm.data.IMAGENET_DEFAULT_STD), \n",
        "        ])\n",
        "\n",
        "train_data = datasets.ImageFolder(os.path.join(train_path), transform = train_transform) \n",
        "valid_data = datasets.ImageFolder(os.path.join(valid_path), transform = test_transform) \n",
        "test_data = datasets.ImageFolder(os.path.join(test_path), transform = test_transform) \n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=1)\n",
        "valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=False, num_workers=1)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=1)\n"
      ],
      "metadata": {
        "id": "vV1QL2GF4yuN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_loader), len(valid_loader), len(test_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTLeLNy-98-y",
        "outputId": "18f231fa-9fc7-4888-904d-ba190b67e286"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "175 22 22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = get_classes(train_path)\n",
        "print(classes, len(classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUyNc-d5_GiI",
        "outputId": "c32b292f-23d4-4bf1-ebce-a9177a07cbba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['brightpixel', 'narrowband', 'narrowbanddrd', 'noise', 'squarepulsednarrowband', 'squiggle', 'squigglesquarepulsednarrowband'] 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloaders = {\n",
        "    \"train\": train_loader,\n",
        "    \"val\": valid_loader\n",
        "}\n",
        "dataset_sizes = {\n",
        "    \"train\": len(train_data),\n",
        "    \"val\": len(valid_data)\n",
        "}"
      ],
      "metadata": {
        "id": "ZwO8JHrj_BFW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLGpKJ6E-J5F",
        "outputId": "2b9baaca-1cc0-465c-9211-4ec84d380ffc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "whG7NP_vUaeY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download pretrained model**"
      ],
      "metadata": {
        "id": "IJMUTJDbUe8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HUB_URL = \"SharanSMenon/swin-transformer-hub:main\"\n",
        "MODEL_NAME = \"swin_tiny_patch4_window7_224\"\n",
        "model = torch.hub.load(HUB_URL, MODEL_NAME, pretrained=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "a1481b55fb714826bcf5058895f7bc2a",
            "37e180599785426898b5e23b6436cff1",
            "eb141f1a65af4cfd9619c786b97ab7d0",
            "99768b8601424da78e5839e7fc043d33",
            "35f384e966a842e4839561639449a1c4",
            "90936f9536bf44c4aecd77e797e46178",
            "c690efb72ac74a37b5ce17947886f3be",
            "9f80ce5ff405435eb617c00b9ea5cb6e",
            "df027177afc243ebac097b9b2b55c11a",
            "7dad2eca9a344c7486c17c7cf1c37249",
            "2cc4a2cf1ca849e0807c221de558a504"
          ]
        },
        "id": "ax0pdw_5-aZ8",
        "outputId": "c39bfbc4-87b0-46b7-ec26-2a61e35d56e3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/hub.py:267: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  \"You are about to download and run code from an untrusted repository. In a future release, this won't \"\n",
            "Downloading: \"https://github.com/SharanSMenon/swin-transformer-hub/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Downloading: \"https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth\" to /root/.cache/torch/hub/checkpoints/swin_tiny_patch4_window7_224.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/109M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a1481b55fb714826bcf5058895f7bc2a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters(): #freeze model\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "5JWfL-W6en4R"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(model.cuda(), (3, 224, 224))"
      ],
      "metadata": {
        "id": "ARlCdWJ7hCAr",
        "outputId": "c19c0055-aea7-40b9-ac9a-b86bc1568b2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 56, 56]           4,704\n",
            "         LayerNorm-2             [-1, 3136, 96]             192\n",
            "        PatchEmbed-3             [-1, 3136, 96]               0\n",
            "           Dropout-4             [-1, 3136, 96]               0\n",
            "         LayerNorm-5             [-1, 3136, 96]             192\n",
            "            Linear-6              [-1, 49, 288]          27,936\n",
            "           Softmax-7            [-1, 3, 49, 49]               0\n",
            "           Dropout-8            [-1, 3, 49, 49]               0\n",
            "            Linear-9               [-1, 49, 96]           9,312\n",
            "          Dropout-10               [-1, 49, 96]               0\n",
            "  WindowAttention-11               [-1, 49, 96]               0\n",
            "         Identity-12             [-1, 3136, 96]               0\n",
            "        LayerNorm-13             [-1, 3136, 96]             192\n",
            "           Linear-14            [-1, 3136, 384]          37,248\n",
            "             GELU-15            [-1, 3136, 384]               0\n",
            "          Dropout-16            [-1, 3136, 384]               0\n",
            "           Linear-17             [-1, 3136, 96]          36,960\n",
            "          Dropout-18             [-1, 3136, 96]               0\n",
            "              Mlp-19             [-1, 3136, 96]               0\n",
            "         Identity-20             [-1, 3136, 96]               0\n",
            "SwinTransformerBlock-21             [-1, 3136, 96]               0\n",
            "        LayerNorm-22             [-1, 3136, 96]             192\n",
            "           Linear-23              [-1, 49, 288]          27,936\n",
            "          Softmax-24            [-1, 3, 49, 49]               0\n",
            "          Dropout-25            [-1, 3, 49, 49]               0\n",
            "           Linear-26               [-1, 49, 96]           9,312\n",
            "          Dropout-27               [-1, 49, 96]               0\n",
            "  WindowAttention-28               [-1, 49, 96]               0\n",
            "         DropPath-29             [-1, 3136, 96]               0\n",
            "        LayerNorm-30             [-1, 3136, 96]             192\n",
            "           Linear-31            [-1, 3136, 384]          37,248\n",
            "             GELU-32            [-1, 3136, 384]               0\n",
            "          Dropout-33            [-1, 3136, 384]               0\n",
            "           Linear-34             [-1, 3136, 96]          36,960\n",
            "          Dropout-35             [-1, 3136, 96]               0\n",
            "              Mlp-36             [-1, 3136, 96]               0\n",
            "         DropPath-37             [-1, 3136, 96]               0\n",
            "SwinTransformerBlock-38             [-1, 3136, 96]               0\n",
            "        LayerNorm-39             [-1, 784, 384]             768\n",
            "           Linear-40             [-1, 784, 192]          73,728\n",
            "     PatchMerging-41             [-1, 784, 192]               0\n",
            "       BasicLayer-42             [-1, 784, 192]               0\n",
            "        LayerNorm-43             [-1, 784, 192]             384\n",
            "           Linear-44              [-1, 49, 576]         111,168\n",
            "          Softmax-45            [-1, 6, 49, 49]               0\n",
            "          Dropout-46            [-1, 6, 49, 49]               0\n",
            "           Linear-47              [-1, 49, 192]          37,056\n",
            "          Dropout-48              [-1, 49, 192]               0\n",
            "  WindowAttention-49              [-1, 49, 192]               0\n",
            "         DropPath-50             [-1, 784, 192]               0\n",
            "        LayerNorm-51             [-1, 784, 192]             384\n",
            "           Linear-52             [-1, 784, 768]         148,224\n",
            "             GELU-53             [-1, 784, 768]               0\n",
            "          Dropout-54             [-1, 784, 768]               0\n",
            "           Linear-55             [-1, 784, 192]         147,648\n",
            "          Dropout-56             [-1, 784, 192]               0\n",
            "              Mlp-57             [-1, 784, 192]               0\n",
            "         DropPath-58             [-1, 784, 192]               0\n",
            "SwinTransformerBlock-59             [-1, 784, 192]               0\n",
            "        LayerNorm-60             [-1, 784, 192]             384\n",
            "           Linear-61              [-1, 49, 576]         111,168\n",
            "          Softmax-62            [-1, 6, 49, 49]               0\n",
            "          Dropout-63            [-1, 6, 49, 49]               0\n",
            "           Linear-64              [-1, 49, 192]          37,056\n",
            "          Dropout-65              [-1, 49, 192]               0\n",
            "  WindowAttention-66              [-1, 49, 192]               0\n",
            "         DropPath-67             [-1, 784, 192]               0\n",
            "        LayerNorm-68             [-1, 784, 192]             384\n",
            "           Linear-69             [-1, 784, 768]         148,224\n",
            "             GELU-70             [-1, 784, 768]               0\n",
            "          Dropout-71             [-1, 784, 768]               0\n",
            "           Linear-72             [-1, 784, 192]         147,648\n",
            "          Dropout-73             [-1, 784, 192]               0\n",
            "              Mlp-74             [-1, 784, 192]               0\n",
            "         DropPath-75             [-1, 784, 192]               0\n",
            "SwinTransformerBlock-76             [-1, 784, 192]               0\n",
            "        LayerNorm-77             [-1, 196, 768]           1,536\n",
            "           Linear-78             [-1, 196, 384]         294,912\n",
            "     PatchMerging-79             [-1, 196, 384]               0\n",
            "       BasicLayer-80             [-1, 196, 384]               0\n",
            "        LayerNorm-81             [-1, 196, 384]             768\n",
            "           Linear-82             [-1, 49, 1152]         443,520\n",
            "          Softmax-83           [-1, 12, 49, 49]               0\n",
            "          Dropout-84           [-1, 12, 49, 49]               0\n",
            "           Linear-85              [-1, 49, 384]         147,840\n",
            "          Dropout-86              [-1, 49, 384]               0\n",
            "  WindowAttention-87              [-1, 49, 384]               0\n",
            "         DropPath-88             [-1, 196, 384]               0\n",
            "        LayerNorm-89             [-1, 196, 384]             768\n",
            "           Linear-90            [-1, 196, 1536]         591,360\n",
            "             GELU-91            [-1, 196, 1536]               0\n",
            "          Dropout-92            [-1, 196, 1536]               0\n",
            "           Linear-93             [-1, 196, 384]         590,208\n",
            "          Dropout-94             [-1, 196, 384]               0\n",
            "              Mlp-95             [-1, 196, 384]               0\n",
            "         DropPath-96             [-1, 196, 384]               0\n",
            "SwinTransformerBlock-97             [-1, 196, 384]               0\n",
            "        LayerNorm-98             [-1, 196, 384]             768\n",
            "           Linear-99             [-1, 49, 1152]         443,520\n",
            "         Softmax-100           [-1, 12, 49, 49]               0\n",
            "         Dropout-101           [-1, 12, 49, 49]               0\n",
            "          Linear-102              [-1, 49, 384]         147,840\n",
            "         Dropout-103              [-1, 49, 384]               0\n",
            " WindowAttention-104              [-1, 49, 384]               0\n",
            "        DropPath-105             [-1, 196, 384]               0\n",
            "       LayerNorm-106             [-1, 196, 384]             768\n",
            "          Linear-107            [-1, 196, 1536]         591,360\n",
            "            GELU-108            [-1, 196, 1536]               0\n",
            "         Dropout-109            [-1, 196, 1536]               0\n",
            "          Linear-110             [-1, 196, 384]         590,208\n",
            "         Dropout-111             [-1, 196, 384]               0\n",
            "             Mlp-112             [-1, 196, 384]               0\n",
            "        DropPath-113             [-1, 196, 384]               0\n",
            "SwinTransformerBlock-114             [-1, 196, 384]               0\n",
            "       LayerNorm-115             [-1, 196, 384]             768\n",
            "          Linear-116             [-1, 49, 1152]         443,520\n",
            "         Softmax-117           [-1, 12, 49, 49]               0\n",
            "         Dropout-118           [-1, 12, 49, 49]               0\n",
            "          Linear-119              [-1, 49, 384]         147,840\n",
            "         Dropout-120              [-1, 49, 384]               0\n",
            " WindowAttention-121              [-1, 49, 384]               0\n",
            "        DropPath-122             [-1, 196, 384]               0\n",
            "       LayerNorm-123             [-1, 196, 384]             768\n",
            "          Linear-124            [-1, 196, 1536]         591,360\n",
            "            GELU-125            [-1, 196, 1536]               0\n",
            "         Dropout-126            [-1, 196, 1536]               0\n",
            "          Linear-127             [-1, 196, 384]         590,208\n",
            "         Dropout-128             [-1, 196, 384]               0\n",
            "             Mlp-129             [-1, 196, 384]               0\n",
            "        DropPath-130             [-1, 196, 384]               0\n",
            "SwinTransformerBlock-131             [-1, 196, 384]               0\n",
            "       LayerNorm-132             [-1, 196, 384]             768\n",
            "          Linear-133             [-1, 49, 1152]         443,520\n",
            "         Softmax-134           [-1, 12, 49, 49]               0\n",
            "         Dropout-135           [-1, 12, 49, 49]               0\n",
            "          Linear-136              [-1, 49, 384]         147,840\n",
            "         Dropout-137              [-1, 49, 384]               0\n",
            " WindowAttention-138              [-1, 49, 384]               0\n",
            "        DropPath-139             [-1, 196, 384]               0\n",
            "       LayerNorm-140             [-1, 196, 384]             768\n",
            "          Linear-141            [-1, 196, 1536]         591,360\n",
            "            GELU-142            [-1, 196, 1536]               0\n",
            "         Dropout-143            [-1, 196, 1536]               0\n",
            "          Linear-144             [-1, 196, 384]         590,208\n",
            "         Dropout-145             [-1, 196, 384]               0\n",
            "             Mlp-146             [-1, 196, 384]               0\n",
            "        DropPath-147             [-1, 196, 384]               0\n",
            "SwinTransformerBlock-148             [-1, 196, 384]               0\n",
            "       LayerNorm-149             [-1, 196, 384]             768\n",
            "          Linear-150             [-1, 49, 1152]         443,520\n",
            "         Softmax-151           [-1, 12, 49, 49]               0\n",
            "         Dropout-152           [-1, 12, 49, 49]               0\n",
            "          Linear-153              [-1, 49, 384]         147,840\n",
            "         Dropout-154              [-1, 49, 384]               0\n",
            " WindowAttention-155              [-1, 49, 384]               0\n",
            "        DropPath-156             [-1, 196, 384]               0\n",
            "       LayerNorm-157             [-1, 196, 384]             768\n",
            "          Linear-158            [-1, 196, 1536]         591,360\n",
            "            GELU-159            [-1, 196, 1536]               0\n",
            "         Dropout-160            [-1, 196, 1536]               0\n",
            "          Linear-161             [-1, 196, 384]         590,208\n",
            "         Dropout-162             [-1, 196, 384]               0\n",
            "             Mlp-163             [-1, 196, 384]               0\n",
            "        DropPath-164             [-1, 196, 384]               0\n",
            "SwinTransformerBlock-165             [-1, 196, 384]               0\n",
            "       LayerNorm-166             [-1, 196, 384]             768\n",
            "          Linear-167             [-1, 49, 1152]         443,520\n",
            "         Softmax-168           [-1, 12, 49, 49]               0\n",
            "         Dropout-169           [-1, 12, 49, 49]               0\n",
            "          Linear-170              [-1, 49, 384]         147,840\n",
            "         Dropout-171              [-1, 49, 384]               0\n",
            " WindowAttention-172              [-1, 49, 384]               0\n",
            "        DropPath-173             [-1, 196, 384]               0\n",
            "       LayerNorm-174             [-1, 196, 384]             768\n",
            "          Linear-175            [-1, 196, 1536]         591,360\n",
            "            GELU-176            [-1, 196, 1536]               0\n",
            "         Dropout-177            [-1, 196, 1536]               0\n",
            "          Linear-178             [-1, 196, 384]         590,208\n",
            "         Dropout-179             [-1, 196, 384]               0\n",
            "             Mlp-180             [-1, 196, 384]               0\n",
            "        DropPath-181             [-1, 196, 384]               0\n",
            "SwinTransformerBlock-182             [-1, 196, 384]               0\n",
            "       LayerNorm-183             [-1, 49, 1536]           3,072\n",
            "          Linear-184              [-1, 49, 768]       1,179,648\n",
            "    PatchMerging-185              [-1, 49, 768]               0\n",
            "      BasicLayer-186              [-1, 49, 768]               0\n",
            "       LayerNorm-187              [-1, 49, 768]           1,536\n",
            "          Linear-188             [-1, 49, 2304]       1,771,776\n",
            "         Softmax-189           [-1, 24, 49, 49]               0\n",
            "         Dropout-190           [-1, 24, 49, 49]               0\n",
            "          Linear-191              [-1, 49, 768]         590,592\n",
            "         Dropout-192              [-1, 49, 768]               0\n",
            " WindowAttention-193              [-1, 49, 768]               0\n",
            "        DropPath-194              [-1, 49, 768]               0\n",
            "       LayerNorm-195              [-1, 49, 768]           1,536\n",
            "          Linear-196             [-1, 49, 3072]       2,362,368\n",
            "            GELU-197             [-1, 49, 3072]               0\n",
            "         Dropout-198             [-1, 49, 3072]               0\n",
            "          Linear-199              [-1, 49, 768]       2,360,064\n",
            "         Dropout-200              [-1, 49, 768]               0\n",
            "             Mlp-201              [-1, 49, 768]               0\n",
            "        DropPath-202              [-1, 49, 768]               0\n",
            "SwinTransformerBlock-203              [-1, 49, 768]               0\n",
            "       LayerNorm-204              [-1, 49, 768]           1,536\n",
            "          Linear-205             [-1, 49, 2304]       1,771,776\n",
            "         Softmax-206           [-1, 24, 49, 49]               0\n",
            "         Dropout-207           [-1, 24, 49, 49]               0\n",
            "          Linear-208              [-1, 49, 768]         590,592\n",
            "         Dropout-209              [-1, 49, 768]               0\n",
            " WindowAttention-210              [-1, 49, 768]               0\n",
            "        DropPath-211              [-1, 49, 768]               0\n",
            "       LayerNorm-212              [-1, 49, 768]           1,536\n",
            "          Linear-213             [-1, 49, 3072]       2,362,368\n",
            "            GELU-214             [-1, 49, 3072]               0\n",
            "         Dropout-215             [-1, 49, 3072]               0\n",
            "          Linear-216              [-1, 49, 768]       2,360,064\n",
            "         Dropout-217              [-1, 49, 768]               0\n",
            "             Mlp-218              [-1, 49, 768]               0\n",
            "        DropPath-219              [-1, 49, 768]               0\n",
            "SwinTransformerBlock-220              [-1, 49, 768]               0\n",
            "      BasicLayer-221              [-1, 49, 768]               0\n",
            "       LayerNorm-222              [-1, 49, 768]           1,536\n",
            "AdaptiveAvgPool1d-223               [-1, 768, 1]               0\n",
            "          Linear-224                 [-1, 1000]         769,000\n",
            "================================================================\n",
            "Total params: 28,265,032\n",
            "Trainable params: 0\n",
            "Non-trainable params: 28,265,032\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 252.99\n",
            "Params size (MB): 107.82\n",
            "Estimated Total Size (MB): 361.39\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "yKoQ5MYpkz2L",
        "outputId": "24ccf109-2e48-4606-dad5-5b19e072077e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SwinTransformer(\n",
              "  (patch_embed): PatchEmbed(\n",
              "    (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
              "    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "  (layers): ModuleList(\n",
              "    (0): BasicLayer(\n",
              "      dim=96, input_resolution=(56, 56), depth=2\n",
              "      (blocks): ModuleList(\n",
              "        (0): SwinTransformerBlock(\n",
              "          dim=96, input_resolution=(56, 56), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0\n",
              "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): WindowAttention(\n",
              "            dim=96, window_size=(7, 7), num_heads=3\n",
              "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "            (softmax): Softmax(dim=-1)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): SwinTransformerBlock(\n",
              "          dim=96, input_resolution=(56, 56), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0\n",
              "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): WindowAttention(\n",
              "            dim=96, window_size=(7, 7), num_heads=3\n",
              "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "            (softmax): Softmax(dim=-1)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.009)\n",
              "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (downsample): PatchMerging(\n",
              "        input_resolution=(56, 56), dim=96\n",
              "        (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
              "        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicLayer(\n",
              "      dim=192, input_resolution=(28, 28), depth=2\n",
              "      (blocks): ModuleList(\n",
              "        (0): SwinTransformerBlock(\n",
              "          dim=192, input_resolution=(28, 28), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0\n",
              "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): WindowAttention(\n",
              "            dim=192, window_size=(7, 7), num_heads=6\n",
              "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "            (softmax): Softmax(dim=-1)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.018)\n",
              "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): SwinTransformerBlock(\n",
              "          dim=192, input_resolution=(28, 28), num_heads=6, window_size=7, shift_size=3, mlp_ratio=4.0\n",
              "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): WindowAttention(\n",
              "            dim=192, window_size=(7, 7), num_heads=6\n",
              "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "            (softmax): Softmax(dim=-1)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.027)\n",
              "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (downsample): PatchMerging(\n",
              "        input_resolution=(28, 28), dim=192\n",
              "        (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
              "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (2): BasicLayer(\n",
              "      dim=384, input_resolution=(14, 14), depth=6\n",
              "      (blocks): ModuleList(\n",
              "        (0): SwinTransformerBlock(\n",
              "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=0, mlp_ratio=4.0\n",
              "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): WindowAttention(\n",
              "            dim=384, window_size=(7, 7), num_heads=12\n",
              "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "            (softmax): Softmax(dim=-1)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.036)\n",
              "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): SwinTransformerBlock(\n",
              "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=3, mlp_ratio=4.0\n",
              "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): WindowAttention(\n",
              "            dim=384, window_size=(7, 7), num_heads=12\n",
              "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "            (softmax): Softmax(dim=-1)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.045)\n",
              "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): SwinTransformerBlock(\n",
              "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=0, mlp_ratio=4.0\n",
              "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): WindowAttention(\n",
              "            dim=384, window_size=(7, 7), num_heads=12\n",
              "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "            (softmax): Softmax(dim=-1)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.055)\n",
              "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): SwinTransformerBlock(\n",
              "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=3, mlp_ratio=4.0\n",
              "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): WindowAttention(\n",
              "            dim=384, window_size=(7, 7), num_heads=12\n",
              "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "            (softmax): Softmax(dim=-1)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.064)\n",
              "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): SwinTransformerBlock(\n",
              "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=0, mlp_ratio=4.0\n",
              "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): WindowAttention(\n",
              "            dim=384, window_size=(7, 7), num_heads=12\n",
              "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "            (softmax): Softmax(dim=-1)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.073)\n",
              "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): SwinTransformerBlock(\n",
              "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=3, mlp_ratio=4.0\n",
              "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): WindowAttention(\n",
              "            dim=384, window_size=(7, 7), num_heads=12\n",
              "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "            (softmax): Softmax(dim=-1)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.082)\n",
              "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (downsample): PatchMerging(\n",
              "        input_resolution=(14, 14), dim=384\n",
              "        (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
              "        (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (3): BasicLayer(\n",
              "      dim=768, input_resolution=(7, 7), depth=2\n",
              "      (blocks): ModuleList(\n",
              "        (0): SwinTransformerBlock(\n",
              "          dim=768, input_resolution=(7, 7), num_heads=24, window_size=7, shift_size=0, mlp_ratio=4.0\n",
              "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): WindowAttention(\n",
              "            dim=768, window_size=(7, 7), num_heads=24\n",
              "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "            (softmax): Softmax(dim=-1)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.091)\n",
              "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): SwinTransformerBlock(\n",
              "          dim=768, input_resolution=(7, 7), num_heads=24, window_size=7, shift_size=0, mlp_ratio=4.0\n",
              "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): WindowAttention(\n",
              "            dim=768, window_size=(7, 7), num_heads=24\n",
              "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "            (softmax): Softmax(dim=-1)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.100)\n",
              "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
              "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers[3]"
      ],
      "metadata": {
        "id": "mdrss48dktR0",
        "outputId": "a3b20d8b-4c69-4a7c-f1e6-1e2554e6c1c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BasicLayer(\n",
              "  dim=768, input_resolution=(7, 7), depth=2\n",
              "  (blocks): ModuleList(\n",
              "    (0): SwinTransformerBlock(\n",
              "      dim=768, input_resolution=(7, 7), num_heads=24, window_size=7, shift_size=0, mlp_ratio=4.0\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): WindowAttention(\n",
              "        dim=768, window_size=(7, 7), num_heads=24\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        (softmax): Softmax(dim=-1)\n",
              "      )\n",
              "      (drop_path): DropPath(drop_prob=0.091)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate=none)\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (1): SwinTransformerBlock(\n",
              "      dim=768, input_resolution=(7, 7), num_heads=24, window_size=7, shift_size=0, mlp_ratio=4.0\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): WindowAttention(\n",
              "        dim=768, window_size=(7, 7), num_heads=24\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        (softmax): Softmax(dim=-1)\n",
              "      )\n",
              "      (drop_path): DropPath(drop_prob=0.100)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate=none)\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.layers[3].parameters(): #unfreeze model\n",
        "    param.requires_grad = True\n",
        "\n",
        "summary(model.cuda(), (3, 224, 224))"
      ],
      "metadata": {
        "id": "gmb_vq12khYW",
        "outputId": "13434631-e619-42be-dcaf-4ca60570e7e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 56, 56]           4,704\n",
            "         LayerNorm-2             [-1, 3136, 96]             192\n",
            "        PatchEmbed-3             [-1, 3136, 96]               0\n",
            "           Dropout-4             [-1, 3136, 96]               0\n",
            "         LayerNorm-5             [-1, 3136, 96]             192\n",
            "            Linear-6              [-1, 49, 288]          27,936\n",
            "           Softmax-7            [-1, 3, 49, 49]               0\n",
            "           Dropout-8            [-1, 3, 49, 49]               0\n",
            "            Linear-9               [-1, 49, 96]           9,312\n",
            "          Dropout-10               [-1, 49, 96]               0\n",
            "  WindowAttention-11               [-1, 49, 96]               0\n",
            "         Identity-12             [-1, 3136, 96]               0\n",
            "        LayerNorm-13             [-1, 3136, 96]             192\n",
            "           Linear-14            [-1, 3136, 384]          37,248\n",
            "             GELU-15            [-1, 3136, 384]               0\n",
            "          Dropout-16            [-1, 3136, 384]               0\n",
            "           Linear-17             [-1, 3136, 96]          36,960\n",
            "          Dropout-18             [-1, 3136, 96]               0\n",
            "              Mlp-19             [-1, 3136, 96]               0\n",
            "         Identity-20             [-1, 3136, 96]               0\n",
            "SwinTransformerBlock-21             [-1, 3136, 96]               0\n",
            "        LayerNorm-22             [-1, 3136, 96]             192\n",
            "           Linear-23              [-1, 49, 288]          27,936\n",
            "          Softmax-24            [-1, 3, 49, 49]               0\n",
            "          Dropout-25            [-1, 3, 49, 49]               0\n",
            "           Linear-26               [-1, 49, 96]           9,312\n",
            "          Dropout-27               [-1, 49, 96]               0\n",
            "  WindowAttention-28               [-1, 49, 96]               0\n",
            "         DropPath-29             [-1, 3136, 96]               0\n",
            "        LayerNorm-30             [-1, 3136, 96]             192\n",
            "           Linear-31            [-1, 3136, 384]          37,248\n",
            "             GELU-32            [-1, 3136, 384]               0\n",
            "          Dropout-33            [-1, 3136, 384]               0\n",
            "           Linear-34             [-1, 3136, 96]          36,960\n",
            "          Dropout-35             [-1, 3136, 96]               0\n",
            "              Mlp-36             [-1, 3136, 96]               0\n",
            "         DropPath-37             [-1, 3136, 96]               0\n",
            "SwinTransformerBlock-38             [-1, 3136, 96]               0\n",
            "        LayerNorm-39             [-1, 784, 384]             768\n",
            "           Linear-40             [-1, 784, 192]          73,728\n",
            "     PatchMerging-41             [-1, 784, 192]               0\n",
            "       BasicLayer-42             [-1, 784, 192]               0\n",
            "        LayerNorm-43             [-1, 784, 192]             384\n",
            "           Linear-44              [-1, 49, 576]         111,168\n",
            "          Softmax-45            [-1, 6, 49, 49]               0\n",
            "          Dropout-46            [-1, 6, 49, 49]               0\n",
            "           Linear-47              [-1, 49, 192]          37,056\n",
            "          Dropout-48              [-1, 49, 192]               0\n",
            "  WindowAttention-49              [-1, 49, 192]               0\n",
            "         DropPath-50             [-1, 784, 192]               0\n",
            "        LayerNorm-51             [-1, 784, 192]             384\n",
            "           Linear-52             [-1, 784, 768]         148,224\n",
            "             GELU-53             [-1, 784, 768]               0\n",
            "          Dropout-54             [-1, 784, 768]               0\n",
            "           Linear-55             [-1, 784, 192]         147,648\n",
            "          Dropout-56             [-1, 784, 192]               0\n",
            "              Mlp-57             [-1, 784, 192]               0\n",
            "         DropPath-58             [-1, 784, 192]               0\n",
            "SwinTransformerBlock-59             [-1, 784, 192]               0\n",
            "        LayerNorm-60             [-1, 784, 192]             384\n",
            "           Linear-61              [-1, 49, 576]         111,168\n",
            "          Softmax-62            [-1, 6, 49, 49]               0\n",
            "          Dropout-63            [-1, 6, 49, 49]               0\n",
            "           Linear-64              [-1, 49, 192]          37,056\n",
            "          Dropout-65              [-1, 49, 192]               0\n",
            "  WindowAttention-66              [-1, 49, 192]               0\n",
            "         DropPath-67             [-1, 784, 192]               0\n",
            "        LayerNorm-68             [-1, 784, 192]             384\n",
            "           Linear-69             [-1, 784, 768]         148,224\n",
            "             GELU-70             [-1, 784, 768]               0\n",
            "          Dropout-71             [-1, 784, 768]               0\n",
            "           Linear-72             [-1, 784, 192]         147,648\n",
            "          Dropout-73             [-1, 784, 192]               0\n",
            "              Mlp-74             [-1, 784, 192]               0\n",
            "         DropPath-75             [-1, 784, 192]               0\n",
            "SwinTransformerBlock-76             [-1, 784, 192]               0\n",
            "        LayerNorm-77             [-1, 196, 768]           1,536\n",
            "           Linear-78             [-1, 196, 384]         294,912\n",
            "     PatchMerging-79             [-1, 196, 384]               0\n",
            "       BasicLayer-80             [-1, 196, 384]               0\n",
            "        LayerNorm-81             [-1, 196, 384]             768\n",
            "           Linear-82             [-1, 49, 1152]         443,520\n",
            "          Softmax-83           [-1, 12, 49, 49]               0\n",
            "          Dropout-84           [-1, 12, 49, 49]               0\n",
            "           Linear-85              [-1, 49, 384]         147,840\n",
            "          Dropout-86              [-1, 49, 384]               0\n",
            "  WindowAttention-87              [-1, 49, 384]               0\n",
            "         DropPath-88             [-1, 196, 384]               0\n",
            "        LayerNorm-89             [-1, 196, 384]             768\n",
            "           Linear-90            [-1, 196, 1536]         591,360\n",
            "             GELU-91            [-1, 196, 1536]               0\n",
            "          Dropout-92            [-1, 196, 1536]               0\n",
            "           Linear-93             [-1, 196, 384]         590,208\n",
            "          Dropout-94             [-1, 196, 384]               0\n",
            "              Mlp-95             [-1, 196, 384]               0\n",
            "         DropPath-96             [-1, 196, 384]               0\n",
            "SwinTransformerBlock-97             [-1, 196, 384]               0\n",
            "        LayerNorm-98             [-1, 196, 384]             768\n",
            "           Linear-99             [-1, 49, 1152]         443,520\n",
            "         Softmax-100           [-1, 12, 49, 49]               0\n",
            "         Dropout-101           [-1, 12, 49, 49]               0\n",
            "          Linear-102              [-1, 49, 384]         147,840\n",
            "         Dropout-103              [-1, 49, 384]               0\n",
            " WindowAttention-104              [-1, 49, 384]               0\n",
            "        DropPath-105             [-1, 196, 384]               0\n",
            "       LayerNorm-106             [-1, 196, 384]             768\n",
            "          Linear-107            [-1, 196, 1536]         591,360\n",
            "            GELU-108            [-1, 196, 1536]               0\n",
            "         Dropout-109            [-1, 196, 1536]               0\n",
            "          Linear-110             [-1, 196, 384]         590,208\n",
            "         Dropout-111             [-1, 196, 384]               0\n",
            "             Mlp-112             [-1, 196, 384]               0\n",
            "        DropPath-113             [-1, 196, 384]               0\n",
            "SwinTransformerBlock-114             [-1, 196, 384]               0\n",
            "       LayerNorm-115             [-1, 196, 384]             768\n",
            "          Linear-116             [-1, 49, 1152]         443,520\n",
            "         Softmax-117           [-1, 12, 49, 49]               0\n",
            "         Dropout-118           [-1, 12, 49, 49]               0\n",
            "          Linear-119              [-1, 49, 384]         147,840\n",
            "         Dropout-120              [-1, 49, 384]               0\n",
            " WindowAttention-121              [-1, 49, 384]               0\n",
            "        DropPath-122             [-1, 196, 384]               0\n",
            "       LayerNorm-123             [-1, 196, 384]             768\n",
            "          Linear-124            [-1, 196, 1536]         591,360\n",
            "            GELU-125            [-1, 196, 1536]               0\n",
            "         Dropout-126            [-1, 196, 1536]               0\n",
            "          Linear-127             [-1, 196, 384]         590,208\n",
            "         Dropout-128             [-1, 196, 384]               0\n",
            "             Mlp-129             [-1, 196, 384]               0\n",
            "        DropPath-130             [-1, 196, 384]               0\n",
            "SwinTransformerBlock-131             [-1, 196, 384]               0\n",
            "       LayerNorm-132             [-1, 196, 384]             768\n",
            "          Linear-133             [-1, 49, 1152]         443,520\n",
            "         Softmax-134           [-1, 12, 49, 49]               0\n",
            "         Dropout-135           [-1, 12, 49, 49]               0\n",
            "          Linear-136              [-1, 49, 384]         147,840\n",
            "         Dropout-137              [-1, 49, 384]               0\n",
            " WindowAttention-138              [-1, 49, 384]               0\n",
            "        DropPath-139             [-1, 196, 384]               0\n",
            "       LayerNorm-140             [-1, 196, 384]             768\n",
            "          Linear-141            [-1, 196, 1536]         591,360\n",
            "            GELU-142            [-1, 196, 1536]               0\n",
            "         Dropout-143            [-1, 196, 1536]               0\n",
            "          Linear-144             [-1, 196, 384]         590,208\n",
            "         Dropout-145             [-1, 196, 384]               0\n",
            "             Mlp-146             [-1, 196, 384]               0\n",
            "        DropPath-147             [-1, 196, 384]               0\n",
            "SwinTransformerBlock-148             [-1, 196, 384]               0\n",
            "       LayerNorm-149             [-1, 196, 384]             768\n",
            "          Linear-150             [-1, 49, 1152]         443,520\n",
            "         Softmax-151           [-1, 12, 49, 49]               0\n",
            "         Dropout-152           [-1, 12, 49, 49]               0\n",
            "          Linear-153              [-1, 49, 384]         147,840\n",
            "         Dropout-154              [-1, 49, 384]               0\n",
            " WindowAttention-155              [-1, 49, 384]               0\n",
            "        DropPath-156             [-1, 196, 384]               0\n",
            "       LayerNorm-157             [-1, 196, 384]             768\n",
            "          Linear-158            [-1, 196, 1536]         591,360\n",
            "            GELU-159            [-1, 196, 1536]               0\n",
            "         Dropout-160            [-1, 196, 1536]               0\n",
            "          Linear-161             [-1, 196, 384]         590,208\n",
            "         Dropout-162             [-1, 196, 384]               0\n",
            "             Mlp-163             [-1, 196, 384]               0\n",
            "        DropPath-164             [-1, 196, 384]               0\n",
            "SwinTransformerBlock-165             [-1, 196, 384]               0\n",
            "       LayerNorm-166             [-1, 196, 384]             768\n",
            "          Linear-167             [-1, 49, 1152]         443,520\n",
            "         Softmax-168           [-1, 12, 49, 49]               0\n",
            "         Dropout-169           [-1, 12, 49, 49]               0\n",
            "          Linear-170              [-1, 49, 384]         147,840\n",
            "         Dropout-171              [-1, 49, 384]               0\n",
            " WindowAttention-172              [-1, 49, 384]               0\n",
            "        DropPath-173             [-1, 196, 384]               0\n",
            "       LayerNorm-174             [-1, 196, 384]             768\n",
            "          Linear-175            [-1, 196, 1536]         591,360\n",
            "            GELU-176            [-1, 196, 1536]               0\n",
            "         Dropout-177            [-1, 196, 1536]               0\n",
            "          Linear-178             [-1, 196, 384]         590,208\n",
            "         Dropout-179             [-1, 196, 384]               0\n",
            "             Mlp-180             [-1, 196, 384]               0\n",
            "        DropPath-181             [-1, 196, 384]               0\n",
            "SwinTransformerBlock-182             [-1, 196, 384]               0\n",
            "       LayerNorm-183             [-1, 49, 1536]           3,072\n",
            "          Linear-184              [-1, 49, 768]       1,179,648\n",
            "    PatchMerging-185              [-1, 49, 768]               0\n",
            "      BasicLayer-186              [-1, 49, 768]               0\n",
            "       LayerNorm-187              [-1, 49, 768]           1,536\n",
            "          Linear-188             [-1, 49, 2304]       1,771,776\n",
            "         Softmax-189           [-1, 24, 49, 49]               0\n",
            "         Dropout-190           [-1, 24, 49, 49]               0\n",
            "          Linear-191              [-1, 49, 768]         590,592\n",
            "         Dropout-192              [-1, 49, 768]               0\n",
            " WindowAttention-193              [-1, 49, 768]               0\n",
            "        DropPath-194              [-1, 49, 768]               0\n",
            "       LayerNorm-195              [-1, 49, 768]           1,536\n",
            "          Linear-196             [-1, 49, 3072]       2,362,368\n",
            "            GELU-197             [-1, 49, 3072]               0\n",
            "         Dropout-198             [-1, 49, 3072]               0\n",
            "          Linear-199              [-1, 49, 768]       2,360,064\n",
            "         Dropout-200              [-1, 49, 768]               0\n",
            "             Mlp-201              [-1, 49, 768]               0\n",
            "        DropPath-202              [-1, 49, 768]               0\n",
            "SwinTransformerBlock-203              [-1, 49, 768]               0\n",
            "       LayerNorm-204              [-1, 49, 768]           1,536\n",
            "          Linear-205             [-1, 49, 2304]       1,771,776\n",
            "         Softmax-206           [-1, 24, 49, 49]               0\n",
            "         Dropout-207           [-1, 24, 49, 49]               0\n",
            "          Linear-208              [-1, 49, 768]         590,592\n",
            "         Dropout-209              [-1, 49, 768]               0\n",
            " WindowAttention-210              [-1, 49, 768]               0\n",
            "        DropPath-211              [-1, 49, 768]               0\n",
            "       LayerNorm-212              [-1, 49, 768]           1,536\n",
            "          Linear-213             [-1, 49, 3072]       2,362,368\n",
            "            GELU-214             [-1, 49, 3072]               0\n",
            "         Dropout-215             [-1, 49, 3072]               0\n",
            "          Linear-216              [-1, 49, 768]       2,360,064\n",
            "         Dropout-217              [-1, 49, 768]               0\n",
            "             Mlp-218              [-1, 49, 768]               0\n",
            "        DropPath-219              [-1, 49, 768]               0\n",
            "SwinTransformerBlock-220              [-1, 49, 768]               0\n",
            "      BasicLayer-221              [-1, 49, 768]               0\n",
            "       LayerNorm-222              [-1, 49, 768]           1,536\n",
            "AdaptiveAvgPool1d-223               [-1, 768, 1]               0\n",
            "          Linear-224                 [-1, 1000]         769,000\n",
            "================================================================\n",
            "Total params: 28,265,032\n",
            "Trainable params: 14,175,744\n",
            "Non-trainable params: 14,089,288\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 252.99\n",
            "Params size (MB): 107.82\n",
            "Estimated Total Size (MB): 361.39\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Add classifier**"
      ],
      "metadata": {
        "id": "Jp7Y_tDOUjOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "n_inputs = model.head.in_features\n",
        "model.head = nn.Sequential(\n",
        "    nn.Linear(n_inputs, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(512, 7)\n",
        ")\n",
        "model = model.to(device)\n",
        "print(model.head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpC9O0p1-ifm",
        "outputId": "013f6d6b-64a8-4bbf-d5b0-b3f6c0612e78"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=768, out_features=512, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Dropout(p=0.3, inplace=False)\n",
            "  (3): Linear(in_features=512, out_features=7, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = LabelSmoothingCrossEntropy()\n",
        "criterion = criterion.to(device)\n",
        "optimizer = optim.AdamW(model.head.parameters(), lr=0.001)\n",
        "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.97)"
      ],
      "metadata": {
        "id": "g6vwfvYz-u1g"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "VFepDFm7UuFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import copy\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=10):\n",
        "    since = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print(\"-\"*10)\n",
        "        \n",
        "        for phase in ['train', 'val']: # We do training and validation phase per epoch\n",
        "            if phase == 'train':\n",
        "                model.train() # model to training mode\n",
        "            else:\n",
        "                model.eval() # model to evaluate\n",
        "            \n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0.0\n",
        "            \n",
        "            for inputs, labels in tqdm(dataloaders[phase]):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                \n",
        "                optimizer.zero_grad()\n",
        "                \n",
        "                with torch.set_grad_enabled(phase == 'train'): # no autograd makes validation go faster\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1) # used for accuracy\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    \n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                \n",
        "            if phase == 'train':\n",
        "                scheduler.step() # step at end of epoch\n",
        "            \n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc =  running_corrects.double() / dataset_sizes[phase]\n",
        "            \n",
        "            print(\"{} Loss: {:.4f} Acc: {:.4f}\".format(phase, epoch_loss, epoch_acc))\n",
        "            \n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict()) # keep the best validation accuracy model\n",
        "        print()\n",
        "    time_elapsed = time.time() - since # slight error\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print(\"Best Val Acc: {:.4f}\".format(best_acc))\n",
        "    \n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "metadata": {
        "id": "XpjST4MI-yz9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SDtJ2nRFnE5",
        "outputId": "2f5310e9-7ff9-48dc-d82c-0e0e8bd32650"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/19\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 175/175 [15:03<00:00,  5.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 1.1277 Acc: 0.7021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [02:19<00:00,  6.33s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 1.0019 Acc: 0.7657\n",
            "\n",
            "Epoch 1/19\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 175/175 [01:23<00:00,  2.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 1.0574 Acc: 0.7370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:09<00:00,  2.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 1.0312 Acc: 0.7443\n",
            "\n",
            "Epoch 2/19\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 175/175 [01:22<00:00,  2.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 1.0262 Acc: 0.7486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:09<00:00,  2.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 1.0262 Acc: 0.7486\n",
            "\n",
            "Epoch 3/19\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 175/175 [01:20<00:00,  2.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 1.0104 Acc: 0.7636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:09<00:00,  2.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.9868 Acc: 0.7729\n",
            "\n",
            "Epoch 4/19\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 175/175 [01:19<00:00,  2.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.9973 Acc: 0.7650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:09<00:00,  2.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.9427 Acc: 0.8000\n",
            "\n",
            "Epoch 5/19\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 175/175 [01:18<00:00,  2.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.9928 Acc: 0.7696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:09<00:00,  2.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.9317 Acc: 0.7943\n",
            "\n",
            "Epoch 6/19\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 175/175 [01:19<00:00,  2.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.9891 Acc: 0.7729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:09<00:00,  2.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.9213 Acc: 0.7943\n",
            "\n",
            "Epoch 7/19\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 175/175 [01:18<00:00,  2.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.9723 Acc: 0.7762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:10<00:00,  2.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.9258 Acc: 0.7943\n",
            "\n",
            "Epoch 8/19\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 175/175 [01:18<00:00,  2.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.9785 Acc: 0.7788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:09<00:00,  2.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.9214 Acc: 0.8014\n",
            "\n",
            "Epoch 9/19\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 175/175 [01:19<00:00,  2.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.9689 Acc: 0.7780\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:09<00:00,  2.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.9578 Acc: 0.7871\n",
            "\n",
            "Epoch 10/19\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 175/175 [01:18<00:00,  2.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.9732 Acc: 0.7784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:09<00:00,  2.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.9285 Acc: 0.7971\n",
            "\n",
            "Epoch 11/19\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 175/175 [01:19<00:00,  2.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.9623 Acc: 0.7811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:09<00:00,  2.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.9069 Acc: 0.8071\n",
            "\n",
            "Epoch 12/19\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 175/175 [01:19<00:00,  2.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.9481 Acc: 0.7864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:09<00:00,  2.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.9131 Acc: 0.7900\n",
            "\n",
            "Epoch 13/19\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 175/175 [01:20<00:00,  2.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.9519 Acc: 0.7852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:09<00:00,  2.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.9165 Acc: 0.8000\n",
            "\n",
            "Epoch 14/19\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 175/175 [01:19<00:00,  2.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.9565 Acc: 0.7848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:09<00:00,  2.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.9392 Acc: 0.8029\n",
            "\n",
            "Epoch 15/19\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 175/175 [01:19<00:00,  2.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.9525 Acc: 0.7864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:10<00:00,  2.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.9260 Acc: 0.7957\n",
            "\n",
            "Epoch 16/19\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 175/175 [01:19<00:00,  2.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.9515 Acc: 0.7845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:10<00:00,  2.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.9095 Acc: 0.7986\n",
            "\n",
            "Epoch 17/19\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 175/175 [01:19<00:00,  2.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.9364 Acc: 0.7955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:09<00:00,  2.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.9097 Acc: 0.8086\n",
            "\n",
            "Epoch 18/19\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 175/175 [01:19<00:00,  2.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.9464 Acc: 0.7902\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:09<00:00,  2.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.9348 Acc: 0.7914\n",
            "\n",
            "Epoch 19/19\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 175/175 [01:19<00:00,  2.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.9449 Acc: 0.7968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:09<00:00,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.8954 Acc: 0.8043\n",
            "\n",
            "Training complete in 45m 40s\n",
            "Best Val Acc: 0.8086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save model**"
      ],
      "metadata": {
        "id": "E0C-NQNOUyQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/MyDrive/dataset/SwinTransformerModel\"\n",
        "\n",
        "torch.save(model_ft.state_dict(), 'model_weights.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA8opvwTIu0m",
        "outputId": "5176aa2c-218c-4c09-fcc1-44710f311a76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/dataset/SwinTransformerModel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "3p3rNoKnU20Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "test_loss = 0.0\n",
        "class_correct = list(0 for i in range(len(classes)))\n",
        "class_total = list(0 for i in range(len(classes)))\n",
        "model_ft.eval()\n",
        "\n",
        "for data, target in tqdm(test_loader):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    with torch.no_grad(): # turn off autograd for faster testing\n",
        "        output = model_ft(data)\n",
        "        loss = criterion(output, target)\n",
        "    test_loss = loss.item() * data.size(0)\n",
        "    _, pred = torch.max(output, 1)\n",
        "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.cpu().numpy())\n",
        "    if len(target) == 32:\n",
        "        for i in range(32):\n",
        "            label = target.data[i]\n",
        "            class_correct[label] += correct[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "test_loss = test_loss / len(test_data)\n",
        "print('Test Loss: {:.4f}'.format(test_loss))\n",
        "for i in range(len(classes)):\n",
        "    if class_total[i] > 0:\n",
        "        print(\"Test Accuracy of %5s: %2d%% (%2d/%2d)\" % (\n",
        "            classes[i], 100*class_correct[i]/class_total[i], np.sum(class_correct[i]), np.sum(class_total[i])\n",
        "        ))\n",
        "    else:\n",
        "        print(\"Test accuracy of %5s: NA\" % (classes[i]))\n",
        "print(\"Test Accuracy of %2d%% (%2d/%2d)\" % (\n",
        "            100*np.sum(class_correct)/np.sum(class_total), np.sum(class_correct), np.sum(class_total)\n",
        "        ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wozEFNg2EOTv",
        "outputId": "1a5e0145-50ad-40eb-d152-6a015487203d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [02:25<00:00,  6.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0382\n",
            "Test Accuracy of brightpixel: 78% (78/100)\n",
            "Test Accuracy of narrowband: 93% (93/100)\n",
            "Test Accuracy of narrowbanddrd: 65% (65/100)\n",
            "Test Accuracy of noise: 99% (99/100)\n",
            "Test Accuracy of squarepulsednarrowband: 79% (79/100)\n",
            "Test Accuracy of squiggle: 78% (78/100)\n",
            "Test Accuracy of squigglesquarepulsednarrowband: 75% (54/72)\n",
            "Test Accuracy of 81% (546/672)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}